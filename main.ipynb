{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0",
      "metadata": {
        "id": "0"
      },
      "source": [
        "### ***                 CH·ª¶ ƒê·ªÄ:  ·ª®NG D·ª§NG M√î H√åNH H·ªåC M√ÅY V√ÄO D·ª∞ ƒêO√ÅN S·ªê ƒêI·ªÜN S·ª¨ D·ª§NG TRONG TH√ÅNG***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1",
      "metadata": {
        "id": "1"
      },
      "source": [
        "# C√°ch s·ª≠ d·ª•ng tr√™n Google Colab:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**B∆∞·ªõc 1: C√†i ƒë·∫∑t kagglehub (ch·∫°y cell ƒë·∫ßu ti√™n)**\n",
        "\n",
        "**B∆∞·ªõc 2: X√°c th·ª±c Kaggle (·ªû ƒë√¢y dataset ta ch·ªçn electric-power-consumption-data-set l√† public n√™n kh√¥ng c·∫ßn x√°c th·ª±c)**\n",
        "\n",
        "**B∆∞·ªõc 3: Ch·∫°y c√°c cell theo th·ª© t·ª±**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2",
      "metadata": {
        "id": "2"
      },
      "outputs": [],
      "source": [
        "#C√†i ƒë·∫∑t v√† import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
        "!pip install kagglehub[pandas-datasets]\n",
        "!pip install optuna\n",
        "!pip install holidays\n",
        "import optuna\n",
        "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import kagglehub\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "import holidays\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU (PREPROCESSING)**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*1.1. T·∫£i v√† L√†m s·∫°ch d·ªØ li·ªáu*\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6DhrjecTJOQK"
      },
      "id": "6DhrjecTJOQK"
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.1 T·∫£i d·ªØ li·ªáu\n",
        "print(\"\\n[1.1] ƒêang t·∫£i d·ªØ li·ªáu t·ª´ Kaggle...\")\n",
        "path = kagglehub.dataset_download(\"uciml/electric-power-consumption-data-set\")\n",
        "df = pd.read_csv(f\"{path}/household_power_consumption.txt\", sep=';',\n",
        "                 parse_dates={'datetime': ['Date', 'Time']},\n",
        "                 infer_datetime_format=True,\n",
        "                 low_memory=False, na_values=['?'])\n",
        "df.set_index('datetime', inplace=True)\n",
        "print(f\"‚úì ƒê√£ t·∫£i {len(df)} d√≤ng d·ªØ li·ªáu t·ª´ {df.index.min()} ƒë·∫øn {df.index.max()}\")"
      ],
      "metadata": {
        "id": "WZvz83_SJbly"
      },
      "id": "WZvz83_SJbly",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "1.2 Gom nh√≥m theo ng√†y\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5luA0Bmmx7GE"
      },
      "id": "5luA0Bmmx7GE"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n[1.2] Gom nh√≥m d·ªØ li·ªáu theo ng√†y...\")\n",
        "df_daily = df['Global_active_power'].resample('D').sum().to_frame()\n",
        "print(f\"‚úì ƒê√£ gom th√†nh {len(df_daily)} ng√†y\")"
      ],
      "metadata": {
        "id": "FbcFFB8cx_3D"
      },
      "id": "FbcFFB8cx_3D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "1.3 X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "el655H10yE-b"
      },
      "id": "el655H10yE-b"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n[1.3] X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu...\")\n",
        "missing_before = df_daily['Global_active_power'].isna().sum()\n",
        "df_daily['Global_active_power'] = df_daily['Global_active_power'].interpolate(method='time')\n",
        "missing_after = df_daily['Global_active_power'].isna().sum()\n",
        "print(f\"‚úì Gi·∫£m t·ª´ {missing_before} ‚Üí {missing_after} gi√° tr·ªã thi·∫øu\")"
      ],
      "metadata": {
        "id": "IL8aS_OyyIVZ"
      },
      "id": "IL8aS_OyyIVZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "1.4 X·ª≠ l√Ω gi√° tr·ªã ngo·∫°i lai\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B4oGCOOnyOKq"
      },
      "id": "B4oGCOOnyOKq"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n[1.4] X·ª≠ l√Ω outliers...\")\n",
        "upper_limit = df_daily['Global_active_power'].quantile(0.99)\n",
        "outliers_count = (df_daily['Global_active_power'] > upper_limit).sum()\n",
        "df_daily['Global_active_power'] = df_daily['Global_active_power'].clip(upper=upper_limit)\n",
        "print(f\"‚úì ƒê√£ x·ª≠ l√Ω {outliers_count} outliers (> {upper_limit:.2f} kWh)\")"
      ],
      "metadata": {
        "id": "yjq_BOYLyTkU"
      },
      "id": "yjq_BOYLyTkU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "1.5 T√≠ch h·ª£p ng√†y l·ªÖ\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EqatQBdxyYGS"
      },
      "id": "EqatQBdxyYGS"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n[1.5] T√≠ch h·ª£p th√¥ng tin ng√†y l·ªÖ...\")\n",
        "fr_holidays = holidays.France()\n",
        "df_daily['is_holiday'] = df_daily.index.map(lambda x: 1 if x in fr_holidays else 0).astype(int)\n",
        "print(f\"‚úì ƒê√£ ƒë√°nh d·∫•u {df_daily['is_holiday'].sum()} ng√†y l·ªÖ\")"
      ],
      "metadata": {
        "id": "NwNK9-L2ybOx"
      },
      "id": "NwNK9-L2ybOx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "1.6 T√≠ch h·ª£p nhi·ªát ƒë·ªô\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RT5YIaiLydx7"
      },
      "id": "RT5YIaiLydx7"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n[1.6] T√≠ch h·ª£p nhi·ªát ƒë·ªô trung b√¨nh theo th√°ng...\")\n",
        "temp_map = {1: 5, 2: 6, 3: 10, 4: 15, 5: 19, 6: 23, 7: 25, 8: 24, 9: 20, 10: 15, 11: 9, 12: 6}\n",
        "df_daily['temp_mean'] = df_daily.index.month.map(temp_map)\n",
        "df_daily['temp_deviation'] = df_daily['temp_mean'] - 15\n",
        "print(f\"‚úì Ph·∫°m vi nhi·ªát ƒë·ªô: {df_daily['temp_mean'].min()}¬∞C - {df_daily['temp_mean'].max()}¬∞C\")"
      ],
      "metadata": {
        "id": "ag2M6UdcymCy"
      },
      "id": "ag2M6UdcymCy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n‚úì HO√ÄN T·∫§T TI·ªÄN X·ª¨ L√ù\")\n",
        "print(f\"C√°c c·ªôt: {df_daily.columns.tolist()}\")\n",
        "print(f\"K√≠ch th∆∞·ªõc: {df_daily.shape}\")"
      ],
      "metadata": {
        "id": "F21ijSDRywSq"
      },
      "id": "F21ijSDRywSq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**2. KH√ÅM PH√Å D·ªÆ LI·ªÜU TR·ª∞C QUAN (EDA)**\n",
        "---\n",
        "2.1. Bi·ªÉu ƒë·ªì 1: Ph√¢n b·ªï\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dx0kxp8A0mVV"
      },
      "id": "dx0kxp8A0mVV"
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "\n",
        "# Bi·ªÉu ƒë·ªì 1: Ph√¢n b·ªï\n",
        "sns.histplot(df_daily['Global_active_power'], kde=True, ax=axes[0,0], color='teal')\n",
        "axes[0,0].set_title('Ph√¢n b·ªï m·ª©c ti√™u th·ª• ƒëi·ªán h√†ng ng√†y')\n",
        "axes[0,0].set_xlabel('ƒêi·ªán nƒÉng (kWh)')\n",
        "\n",
        "# Bi·ªÉu ƒë·ªì 2: Xu h∆∞·ªõng\n",
        "axes[0,1].plot(df_daily['Global_active_power'], alpha=0.3, label='H√†ng ng√†y')\n",
        "axes[0,1].plot(df_daily['Global_active_power'].rolling(30).mean(),\n",
        "               color='red', linewidth=2, label='Trung b√¨nh 30 ng√†y')\n",
        "axes[0,1].set_title('Xu h∆∞·ªõng ti√™u th·ª• ƒëi·ªán qua th·ªùi gian')\n",
        "axes[0,1].legend()\n",
        "axes[0,1].set_ylabel('ƒêi·ªán nƒÉng (kWh)')\n",
        "\n",
        "# Bi·ªÉu ƒë·ªì 3: Theo th√°ng\n",
        "monthly_avg = df_daily.groupby(df_daily.index.month)['Global_active_power'].mean()\n",
        "axes[1,0].bar(monthly_avg.index, monthly_avg.values, color='steelblue')\n",
        "axes[1,0].set_title('Ti√™u th·ª• trung b√¨nh theo th√°ng')\n",
        "axes[1,0].set_xlabel('Th√°ng')\n",
        "axes[1,0].set_ylabel('ƒêi·ªán nƒÉng (kWh)')\n",
        "axes[1,0].set_xticks(range(1, 13))\n",
        "\n",
        "# Bi·ªÉu ƒë·ªì 4: Theo ng√†y trong tu·∫ßn\n",
        "weekly_avg = df_daily.groupby(df_daily.index.dayofweek)['Global_active_power'].mean()\n",
        "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "axes[1,1].bar(range(7), weekly_avg.values, color='coral')\n",
        "axes[1,1].set_title('Ti√™u th·ª• trung b√¨nh theo ng√†y trong tu·∫ßn')\n",
        "axes[1,1].set_xlabel('Ng√†y')\n",
        "axes[1,1].set_ylabel('ƒêi·ªán nƒÉng (kWh)')\n",
        "axes[1,1].set_xticks(range(7))\n",
        "axes[1,1].set_xticklabels(days)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UqyNgeYG0xp1"
      },
      "id": "UqyNgeYG0xp1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## **3.FEATURE ENGINEERING (K·ª∏ THU·∫¨T ƒê·∫∂C TR∆ØNG)**\n",
        "\n",
        "---\n",
        "\n",
        "3.1 T·∫°o c√°c ƒë·∫∑c trwngg n√¢ng cao"
      ],
      "metadata": {
        "id": "xviMQQEtJhgq"
      },
      "id": "xviMQQEtJhgq"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_advance_features(df):\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # ƒê·∫∑c tr∆∞ng th·ªùi gian c∆° b·∫£n\n",
        "    df['dayofweek'] = df.index.dayofweek\n",
        "    df['month'] = df.index.month\n",
        "    df['is_weekend'] = df['dayofweek'].isin([5, 6]).astype(int)\n",
        "\n",
        "    # M√£ h√≥a chu k·ª≥ (sin/cos) - FIX: Th√™m day_sin/day_cos\n",
        "    df['month_sin'] = np.sin(2 * np.pi * df['month']/12)\n",
        "    df['month_cos'] = np.cos(2 * np.pi * df['month']/12)\n",
        "    df['day_sin'] = np.sin(2 * np.pi * df['dayofweek']/7)\n",
        "    df['day_cos'] = np.cos(2 * np.pi * df['dayofweek']/7)\n",
        "\n",
        "    # ƒê·∫∑c tr∆∞ng l·ªãch s·ª≠ (Lags)\n",
        "    df['lag_1'] = df['Global_active_power'].shift(1)\n",
        "    df['lag_7'] = df['Global_active_power'].shift(7)\n",
        "\n",
        "    # ƒê·∫∑c tr∆∞ng c·ª≠a s·ªï tr∆∞·ª£t\n",
        "    df['rolling_mean_7'] = df['Global_active_power'].rolling(window=7).mean().shift(1)\n",
        "    df['rolling_std_7'] = df['Global_active_power'].rolling(window=7).std().shift(1)\n",
        "\n",
        "    # Bi·∫øn t∆∞∆°ng t√°c th√¥ng minh\n",
        "    df['temp_impact'] = df['temp_mean'] * df['lag_1']\n",
        "    df['energy_diff'] = df['lag_1'] - df['rolling_mean_7']\n",
        "\n",
        "    return df.dropna()\n",
        "print(\"\\n[3.1] T·∫°o c√°c ƒë·∫∑c tr∆∞ng...\")\n",
        "data = create_advance_features(df_daily)\n",
        "print(f\"‚úì ƒê√£ t·∫°o {len(data.columns)} c·ªôt ƒë·∫∑c tr∆∞ng\")\n",
        "print(f\"  K√≠ch th∆∞·ªõc sau khi dropna: {data.shape}\")"
      ],
      "metadata": {
        "id": "ohhEIMoQJm_p"
      },
      "id": "ohhEIMoQJm_p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "3.2 Ma tr·∫≠n t∆∞∆°ng quan\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-kw6s7H-1Gr6"
      },
      "id": "-kw6s7H-1Gr6"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Ph√¢n t√≠ch t∆∞∆°ng quan...\")\n",
        "plt.figure(figsize=(14, 10))\n",
        "correlation_matrix = data.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm',\n",
        "            center=0, square=True, linewidths=1)\n",
        "plt.title('Ma tr·∫≠n t∆∞∆°ng quan gi·ªØa c√°c ƒë·∫∑c tr∆∞ng', fontsize=14, pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4ECfmayj1K8j"
      },
      "id": "4ECfmayj1K8j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "3.3 Chu·∫©n h√≥a l·∫°i data d·ª±a tr√™n m·ª©c ƒë·ªô quan tr·ªçng\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R3UFHSyhYlLB"
      },
      "id": "R3UFHSyhYlLB"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n[3.3] L·ªçc ƒë·∫∑c tr∆∞ng quan tr·ªçng...\")\n",
        "target = 'Global_active_power'\n",
        "\n",
        "# Lo·∫°i b·ªè c√°c bi·∫øn th·ª´a th√£i\n",
        "features_to_drop = ['temp_deviation', 'month', 'dayofweek']\n",
        "\n",
        "# T√≠nh t∆∞∆°ng quan v·ªõi target\n",
        "correlations = data.corr()[target].abs().sort_values(ascending=False)\n",
        "threshold = 0.05\n",
        "numeric_features = correlations[correlations > threshold].index.tolist()\n",
        "\n",
        "# T·ªïng h·ª£p danh s√°ch cu·ªëi\n",
        "selected_features = [f for f in numeric_features\n",
        "                    if f != target and f not in features_to_drop]\n",
        "\n",
        "# ƒê·∫£m b·∫£o gi·ªØ c√°c bi·∫øn chu k·ª≥\n",
        "cyclical_features = ['month_sin', 'month_cos', 'day_sin', 'day_cos']\n",
        "for feat in cyclical_features:\n",
        "    if feat not in selected_features and feat in data.columns:\n",
        "        selected_features.append(feat)\n",
        "\n",
        "print(f\"‚úì S·ªë ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c ch·ªçn: {len(selected_features)}\")\n",
        "print(f\"‚úì Danh s√°ch: {selected_features}\")\n",
        "\n",
        "# Chu·∫©n b·ªã d·ªØ li·ªáu\n",
        "X = data[selected_features]\n",
        "y = data[target]\n",
        "\n",
        "print(f\"\\n‚úì HO√ÄN T·∫§T FEATURE ENGINEERING\")\n",
        "print(f\"  Shape: X={X.shape}, y={y.shape}\")"
      ],
      "metadata": {
        "id": "qvRmuQF2Y0Go"
      },
      "id": "qvRmuQF2Y0Go",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. CHIA D·ªÆ LI·ªÜU V√Ä CHU·∫®N H√ìA**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RgZhhTUrKA3I"
      },
      "id": "RgZhhTUrKA3I"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PH·∫¶N 4: CHIA D·ªÆ LI·ªÜU V√Ä CHU·∫®N H√ìA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "n = len(data)\n",
        "train_end = int(n * 0.7)\n",
        "val_end = int(n * 0.85)\n",
        "\n",
        "train_df = data.iloc[:train_end]\n",
        "val_df = data.iloc[train_end:val_end]\n",
        "test_df = data.iloc[val_end:]\n",
        "train_val_df = data.iloc[:val_end]\n",
        "\n",
        "print(f\"\\n‚úì Chia d·ªØ li·ªáu:\")\n",
        "print(f\"  Train:     {len(train_df)} m·∫´u ({train_df.index.min()} ‚Üí {train_df.index.max()})\")\n",
        "print(f\"  Validation: {len(val_df)} m·∫´u ({val_df.index.min()} ‚Üí {val_df.index.max()})\")\n",
        "print(f\"  Test:      {len(test_df)} m·∫´u ({test_df.index.min()} ‚Üí {test_df.index.max()})\")\n",
        "\n",
        "# Chu·∫©n h√≥a\n",
        "scaler = MinMaxScaler()\n",
        "X_train = train_df[selected_features]\n",
        "y_train = train_df[target]\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "X_train_val_scaled = scaler.transform(train_val_df[selected_features])\n",
        "y_train_val = train_val_df[target]\n",
        "\n",
        "print(f\"\\n‚úì ƒê√£ chu·∫©n h√≥a d·ªØ li·ªáu v·ªÅ kho·∫£ng [0, 1]\")\n"
      ],
      "metadata": {
        "id": "dUz5aXsHKYhS"
      },
      "id": "dUz5aXsHKYhS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## **5. D·ª∞ B√ÅO CU·ªêN CHI·∫æU (RECURSIVE FORECASTING)**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "oTvyhMHCKn2y"
      },
      "id": "oTvyhMHCKn2y"
    },
    {
      "cell_type": "code",
      "source": [
        "def recursive_forecast(model, scaler, history_df, selected_features, steps=30):\n",
        "\n",
        "    current_history = history_df.copy()\n",
        "    forecasts = []\n",
        "\n",
        "    fr_holidays = holidays.France()\n",
        "    temp_map = {1: 5, 2: 6, 3: 10, 4: 15, 5: 19, 6: 23, 7: 25,\n",
        "                8: 24, 9: 20, 10: 15, 11: 9, 12: 6}\n",
        "\n",
        "    for step in range(steps):\n",
        "        # T·∫°o ƒë·∫∑c tr∆∞ng t·ª´ l·ªãch s·ª≠\n",
        "        features = create_advance_features(current_history)\n",
        "        X_next = features[selected_features].iloc[-1:]\n",
        "\n",
        "        # D·ª± b√°o\n",
        "        X_next_scaled = scaler.transform(X_next)\n",
        "        y_pred = max(0, model.predict(X_next_scaled)[0])\n",
        "        forecasts.append(y_pred)\n",
        "\n",
        "        # C·∫≠p nh·∫≠t l·ªãch s·ª≠ cho v√≤ng l·∫∑p ti·∫øp theo\n",
        "        next_date = current_history.index[-1] + pd.Timedelta(days=1)\n",
        "        is_h = 1 if next_date in fr_holidays else 0\n",
        "        t_mean = temp_map[next_date.month]\n",
        "        t_dev = t_mean - 15\n",
        "\n",
        "        new_row = pd.DataFrame({\n",
        "            'Global_active_power': [y_pred],\n",
        "            'is_holiday': [is_h],\n",
        "            'temp_mean': [t_mean],\n",
        "            'temp_deviation': [t_dev]\n",
        "        }, index=[next_date])\n",
        "\n",
        "        current_history = pd.concat([current_history, new_row])\n",
        "\n",
        "    return np.array(forecasts)"
      ],
      "metadata": {
        "id": "TB_jTxYLKuKi"
      },
      "id": "TB_jTxYLKuKi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. TH·ª∞C NGHI·ªÜM V√Ä T·ªêI ∆ØU T·ª™NG M√î H√åNH**\n",
        "\n",
        "---\n",
        "\n",
        "6.1. H√†m ƒë√°nh gi√° m√¥ h√¨nh tr√™n Recursive Forecast\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wZ9B6r39MEzT"
      },
      "id": "wZ9B6r39MEzT"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dVwUuMFLiHF-"
      },
      "id": "dVwUuMFLiHF-"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recursive_metrics(model, scaler, df_daily, start_idx, steps=30, selected_features=None):\n",
        "\n",
        "    history_df = df_daily.iloc[start_idx - 60 : start_idx].copy()\n",
        "    actual_series = df_daily.iloc[start_idx : start_idx + steps]['Global_active_power']\n",
        "    current_steps = len(actual_series)\n",
        "\n",
        "    if current_steps == 0:\n",
        "        return None\n",
        "\n",
        "    preds = recursive_forecast(model, scaler, history_df, selected_features, steps=current_steps)\n",
        "    actual = actual_series.values\n",
        "\n",
        "    # T√≠nh c√°c ch·ªâ s·ªë\n",
        "    rmse = np.sqrt(mean_squared_error(actual, preds))\n",
        "    mae = mean_absolute_error(actual, preds)\n",
        "    mape = np.mean(np.abs((actual - preds) / (actual + 1e-10))) * 100\n",
        "    r2 = r2_score(actual, preds)\n",
        "\n",
        "    total_actual = actual.sum()\n",
        "    total_pred = preds.sum()\n",
        "    total_err_pct = abs(total_actual - total_pred) / (total_actual + 1e-10) * 100\n",
        "\n",
        "    return {\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae,\n",
        "        'MAPE': mape,\n",
        "        'R2': r2,\n",
        "        'Total_Err_Pct': total_err_pct,\n",
        "        'Forecasts': preds,\n",
        "        'Actual': actual_series,\n",
        "        'Actual_Sum': total_actual,\n",
        "        'Pred_Sum': total_pred\n",
        "    }\n",
        "\n",
        "print(\"‚úì ƒê√£ kh·ªüi t·∫°o h·ªá th·ªëng d·ª± b√°o cu·ªën chi·∫øu\")"
      ],
      "metadata": {
        "id": "t1ZksuW0MMj6"
      },
      "id": "t1ZksuW0MMj6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "6.2 T·ªêI ∆ØU LINEAR REGRESSION\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "GQVYbgX1jbuv"
      },
      "id": "GQVYbgX1jbuv"
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_linear_regression(df_daily, train_end, val_end, selected_features, n_trials=30):\n",
        "    def objective(trial):\n",
        "        reg_type = trial.suggest_categorical('type', ['ridge', 'lasso'])\n",
        "        alpha = trial.suggest_float('alpha', 0.01, 100.0, log=True)\n",
        "\n",
        "        if reg_type == 'ridge':\n",
        "            model = Ridge(alpha=alpha, random_state=42)\n",
        "        else:\n",
        "            model = Lasso(alpha=alpha, max_iter=10000, random_state=42)\n",
        "\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        train_res = get_recursive_metrics(model, scaler, df_daily,\n",
        "                                         start_idx=train_end-30, steps=30,\n",
        "                                         selected_features=selected_features)\n",
        "        val_res = get_recursive_metrics(model, scaler, df_daily,\n",
        "                                       start_idx=train_end,\n",
        "                                       steps=(val_end - train_end),\n",
        "                                       selected_features=selected_features)\n",
        "\n",
        "        if train_res is None or val_res is None:\n",
        "            return float('inf')\n",
        "\n",
        "        val_rmse = val_res['RMSE']\n",
        "        train_rmse = train_res['RMSE']\n",
        "        gap = abs(val_rmse - train_rmse)\n",
        "\n",
        "        return val_rmse + 0.3 * gap\n",
        "\n",
        "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
        "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "\n",
        "    print(f\"‚úì Best params: {study.best_params}, Best score: {study.best_value:.4f}\")\n",
        "    return study"
      ],
      "metadata": {
        "id": "ZIIFBJxTjjN2"
      },
      "id": "ZIIFBJxTjjN2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "6.3 T·ªêI ∆ØU RANDOM FOREST\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "sT2HqJJajxcu"
      },
      "id": "sT2HqJJajxcu"
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_random_forest(df_daily, train_end, val_end, selected_features, n_trials=30):\n",
        "    def objective(trial):\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "            'max_depth': trial.suggest_int('max_depth', 5, 20),\n",
        "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 2, 10),\n",
        "            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
        "            'random_state': 42,\n",
        "            'n_jobs': -1\n",
        "        }\n",
        "\n",
        "        model = RandomForestRegressor(**params).fit(X_train_scaled, y_train)\n",
        "\n",
        "        tr_res = get_recursive_metrics(model, scaler, df_daily,\n",
        "                                       start_idx=train_end-30, steps=30,\n",
        "                                       selected_features=selected_features)\n",
        "        vl_res = get_recursive_metrics(model, scaler, df_daily,\n",
        "                                       start_idx=train_end,\n",
        "                                       steps=(val_end - train_end),\n",
        "                                       selected_features=selected_features)\n",
        "\n",
        "        if tr_res is None or vl_res is None:\n",
        "            return 99999\n",
        "\n",
        "        val_rmse = vl_res['RMSE']\n",
        "        train_rmse = tr_res['RMSE']\n",
        "        gap = abs(val_rmse - train_rmse)\n",
        "\n",
        "        return val_rmse + 0.5 * gap\n",
        "\n",
        "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
        "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "\n",
        "    print(f\"‚úì Best params: {study.best_params}, Best score: {study.best_value:.4f}\")\n",
        "    return study"
      ],
      "metadata": {
        "id": "4K6pPSmej0a_"
      },
      "id": "4K6pPSmej0a_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "6.4 T·ªêI ∆ØU GRADIENT BOOSTING\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "srGb9mg8j43P"
      },
      "id": "srGb9mg8j43P"
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_gradient_boosting(df_daily, train_end, val_end, selected_features, n_trials=30):\n",
        "    def objective(trial):\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 100, 800),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
        "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "            'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
        "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 2, 10),\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        model = GradientBoostingRegressor(**params).fit(X_train_scaled, y_train)\n",
        "\n",
        "        tr_res = get_recursive_metrics(model, scaler, df_daily,\n",
        "                                       start_idx=train_end-30, steps=30,\n",
        "                                       selected_features=selected_features)\n",
        "        vl_res = get_recursive_metrics(model, scaler, df_daily,\n",
        "                                       start_idx=train_end,\n",
        "                                       steps=(val_end - train_end),\n",
        "                                       selected_features=selected_features)\n",
        "\n",
        "        if tr_res is None or vl_res is None:\n",
        "            return 99999\n",
        "\n",
        "        val_rmse = vl_res['RMSE']\n",
        "        train_rmse = tr_res['RMSE']\n",
        "        gap = abs(val_rmse - train_rmse)\n",
        "\n",
        "        return val_rmse + 0.4 * gap\n",
        "\n",
        "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
        "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "\n",
        "    print(f\"‚úì Best params: {study.best_params}, Best score: {study.best_value:.4f}\")\n",
        "    return study"
      ],
      "metadata": {
        "id": "zwy627P0j8SW"
      },
      "id": "zwy627P0j8SW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "6.5 T·ªêI ∆ØU XGBOOST\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "98OiFxoEkBN-"
      },
      "id": "98OiFxoEkBN-"
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_xgboost(df_daily, train_end, val_end, selected_features, n_trials=30):\n",
        "    def objective(trial):\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
        "            'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
        "            'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 10.0, log=True),\n",
        "            'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 5.0, log=True),\n",
        "            'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
        "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
        "            'random_state': 42,\n",
        "            'tree_method': 'hist',\n",
        "            'n_jobs': -1\n",
        "        }\n",
        "\n",
        "        model = xgb.XGBRegressor(**params).fit(X_train_scaled, y_train)\n",
        "\n",
        "        tr_res = get_recursive_metrics(model, scaler, df_daily,\n",
        "                                       start_idx=train_end-30, steps=30,\n",
        "                                       selected_features=selected_features)\n",
        "        vl_res = get_recursive_metrics(model, scaler, df_daily,\n",
        "                                       start_idx=train_end,\n",
        "                                       steps=(val_end - train_end),\n",
        "                                       selected_features=selected_features)\n",
        "\n",
        "        if tr_res is None or vl_res is None:\n",
        "            return 99999\n",
        "\n",
        "        val_rmse = vl_res['RMSE']\n",
        "        train_rmse = tr_res['RMSE']\n",
        "        gap = abs(val_rmse - train_rmse)\n",
        "\n",
        "        return val_rmse + 0.4 * gap\n",
        "\n",
        "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
        "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "\n",
        "    print(f\"‚úì Best params: {study.best_params}, Best score: {study.best_value:.4f}\")\n",
        "    return study"
      ],
      "metadata": {
        "id": "AJ-wctoUkOzu"
      },
      "id": "AJ-wctoUkOzu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n‚öôÔ∏è  B·∫ÆT ƒê·∫¶U QU√Å TR√åNH T·ªêI ∆ØU (Vui l√≤ng ƒë·ª£i 5-10 ph√∫t)...\")\n",
        "studies = {\n",
        "    'Linear Regression': optimize_linear_regression(df_daily, train_end, val_end, selected_features, n_trials=30),\n",
        "    'Random Forest': optimize_random_forest(df_daily, train_end, val_end, selected_features, n_trials=30),\n",
        "    'Gradient Boosting': optimize_gradient_boosting(df_daily, train_end, val_end, selected_features, n_trials=30),\n",
        "    'XGBoost': optimize_xgboost(df_daily, train_end, val_end, selected_features, n_trials=30)\n",
        "}\n",
        "\n",
        "print(\"\\n‚úì HO√ÄN T·∫§T T·ªêI ∆ØU H√ìA T·∫§T C·∫¢ M√î H√åNH\")"
      ],
      "metadata": {
        "id": "M87vH9Nk3f5y"
      },
      "id": "M87vH9Nk3f5y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7. SO S√ÅNH V√Ä ƒê√ÅNH GI√Å K·∫æT QU·∫¢**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CXLe97bWNEji"
      },
      "id": "CXLe97bWNEji"
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_optimized_models(studies_dict, df_daily, train_end, val_end, selected_features):\n",
        "    \"\"\"So s√°nh t·∫•t c·∫£ c√°c m√¥ h√¨nh ƒë√£ t·ªëi ∆∞u\"\"\"\n",
        "    results = {}\n",
        "\n",
        "    for name, study in studies_dict.items():\n",
        "        print(f\"\\n[ƒê√°nh gi√°] {name}...\")\n",
        "        bp = study.best_params\n",
        "\n",
        "        # Kh·ªüi t·∫°o m√¥ h√¨nh v·ªõi tham s·ªë t·ªët nh·∫•t\n",
        "        if name == 'Linear Regression':\n",
        "            if bp.get('type') == 'ridge':\n",
        "                model = Ridge(alpha=bp['alpha'], random_state=42)\n",
        "            else:\n",
        "                model = Lasso(alpha=bp['alpha'], max_iter=10000, random_state=42)\n",
        "        elif name == 'Random Forest':\n",
        "            model = RandomForestRegressor(**bp, random_state=42, n_jobs=-1)\n",
        "        elif name == 'Gradient Boosting':\n",
        "            model = GradientBoostingRegressor(**bp, random_state=42)\n",
        "        else:\n",
        "            model = xgb.XGBRegressor(**bp, random_state=42, n_jobs=-1)\n",
        "\n",
        "        # ƒê√°nh gi√° tr√™n Train v√† Val\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        train_metrics = get_recursive_metrics(model, scaler, df_daily,\n",
        "                                             start_idx=train_end-30, steps=30,\n",
        "                                             selected_features=selected_features)\n",
        "        val_metrics = get_recursive_metrics(model, scaler, df_daily,\n",
        "                                           start_idx=train_end,\n",
        "                                           steps=(val_end-train_end),\n",
        "                                           selected_features=selected_features)\n",
        "\n",
        "        # Hu·∫•n luy·ªán l·∫°i v·ªõi Train+Val ƒë·ªÉ ƒë√°nh gi√° Test\n",
        "        model.fit(X_train_val_scaled, y_train_val)\n",
        "        test_metrics = get_recursive_metrics(model, scaler, df_daily,\n",
        "                                            start_idx=val_end, steps=30,\n",
        "                                            selected_features=selected_features)\n",
        "\n",
        "        results[name] = {\n",
        "            'Train': train_metrics,\n",
        "            'Val': val_metrics,\n",
        "            'Test': test_metrics,\n",
        "            'Best_Params': bp,\n",
        "            'Model': model\n",
        "        }\n",
        "        print(f\"  ‚úì R2_Test={test_metrics['R2']:.4f}, RMSE_Test={test_metrics['RMSE']:.2f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# So s√°nh c√°c m√¥ h√¨nh\n",
        "final_results = compare_optimized_models(studies, df_daily, train_end, val_end, selected_features)\n",
        "\n",
        "# T·∫°o b·∫£ng t·ªïng h·ª£p\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"B·∫¢NG T·ªîNG H·ª¢P K·∫æT QU·∫¢\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "summary = []\n",
        "for name, m in final_results.items():\n",
        "    summary.append({\n",
        "        'Model': name,\n",
        "        'R2_Train': m['Train']['R2'],\n",
        "        'R2_Val': m['Val']['R2'],\n",
        "        'R2_Test': m['Test']['R2'],\n",
        "        'RMSE_Train': m['Train']['RMSE'],\n",
        "        'RMSE_Val': m['Val']['RMSE'],\n",
        "        'RMSE_Test': m['Test']['RMSE'],\n",
        "        'MAE_Test': m['Test']['MAE'],\n",
        "        'MAPE_Test (%)': m['Test']['MAPE'],\n",
        "        'Total_Err_Test (%)': m['Test']['Total_Err_Pct']\n",
        "    })\n",
        "\n",
        "df_summary = pd.DataFrame(summary).sort_values(by='R2_Test', ascending=False)\n",
        "display(df_summary)\n",
        "\n",
        "# T√¨m m√¥ h√¨nh t·ªët nh·∫•t\n",
        "best_model_name = df_summary.iloc[0]['Model']\n",
        "print(f\"\\nüèÜ M√î H√åNH T·ªêT NH·∫§T: {best_model_name}\")\n",
        "print(f\"   R¬≤ Score: {df_summary.iloc[0]['R2_Test']:.4f}\")\n",
        "print(f\"   RMSE: {df_summary.iloc[0]['RMSE_Test']:.2f} kWh\")\n",
        "print(f\"   MAE: {df_summary.iloc[0]['MAE_Test']:.2f} kWh\")\n",
        "print(f\"   MAPE: {df_summary.iloc[0]['MAPE_Test (%)']:.2f}%\")\n"
      ],
      "metadata": {
        "id": "IzYS5MbzNLQ6"
      },
      "id": "IzYS5MbzNLQ6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8. TR·ª∞C QUAN H√ìA K·∫æT QU·∫¢**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Ac93E4kz5L0Z"
      },
      "id": "Ac93E4kz5L0Z"
    },
    {
      "cell_type": "code",
      "source": [
        "best_result = final_results[best_model_name]['Test']\n",
        "best_model = final_results[best_model_name]['Model']\n",
        "\n",
        "# Bi·ªÉu ƒë·ªì 1: So s√°nh D·ª± b√°o vs Th·ª±c t·∫ø\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "\n",
        "# 1.1 ƒê∆∞·ªùng th·ªùi gian\n",
        "axes[0, 0].plot(best_result['Actual'].index, best_result['Actual'].values,\n",
        "               label='Th·ª±c t·∫ø', linewidth=2, marker='o', markersize=4)\n",
        "axes[0, 0].plot(best_result['Actual'].index, best_result['Forecasts'],\n",
        "               label=f'D·ª± b√°o ({best_model_name})', linewidth=2,\n",
        "               marker='s', markersize=4, linestyle='--')\n",
        "axes[0, 0].set_title('So s√°nh D·ª± b√°o vs Th·ª±c t·∫ø (30 ng√†y Test)')\n",
        "axes[0, 0].set_xlabel('Ng√†y')\n",
        "axes[0, 0].set_ylabel('ƒêi·ªán nƒÉng (kWh)')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 1.2 Scatter plot\n",
        "axes[0, 1].scatter(best_result['Actual'].values, best_result['Forecasts'], alpha=0.6)\n",
        "min_val = min(best_result['Actual'].values.min(), best_result['Forecasts'].min())\n",
        "max_val = max(best_result['Actual'].values.max(), best_result['Forecasts'].max())\n",
        "axes[0, 1].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
        "axes[0, 1].set_title('Scatter Plot: Th·ª±c t·∫ø vs D·ª± b√°o')\n",
        "axes[0, 1].set_xlabel('Th·ª±c t·∫ø (kWh)')\n",
        "axes[0, 1].set_ylabel('D·ª± b√°o (kWh)')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 1.3 Residuals (Sai s·ªë)\n",
        "residuals = best_result['Actual'].values - best_result['Forecasts']\n",
        "axes[1, 0].bar(range(len(residuals)), residuals, color=['red' if x < 0 else 'green' for x in residuals])\n",
        "axes[1, 0].axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
        "axes[1, 0].set_title('Residuals (Sai s·ªë d·ª± b√°o)')\n",
        "axes[1, 0].set_xlabel('Ng√†y')\n",
        "axes[1, 0].set_ylabel('Sai s·ªë (kWh)')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 1.4 Ph√¢n b·ªï residuals\n",
        "axes[1, 1].hist(residuals, bins=15, edgecolor='black', alpha=0.7)\n",
        "axes[1, 1].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
        "axes[1, 1].set_title('Ph√¢n b·ªï sai s·ªë d·ª± b√°o')\n",
        "axes[1, 1].set_xlabel('Sai s·ªë (kWh)')\n",
        "axes[1, 1].set_ylabel('T·∫ßn su·∫•t')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Bi·ªÉu ƒë·ªì 2: So s√°nh hi·ªáu su·∫•t c√°c m√¥ h√¨nh\n",
        "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
        "\n",
        "models = df_summary['Model'].values\n",
        "r2_scores = df_summary['R2_Test'].values\n",
        "rmse_scores = df_summary['RMSE_Test'].values\n",
        "mape_scores = df_summary['MAPE_Test (%)'].values\n",
        "\n",
        "# 2.1 R¬≤ Score\n",
        "axes[0].barh(models, r2_scores, color='steelblue')\n",
        "axes[0].set_xlabel('R¬≤ Score')\n",
        "axes[0].set_title('So s√°nh R¬≤ Score')\n",
        "axes[0].grid(True, alpha=0.3, axis='x')\n",
        "for i, v in enumerate(r2_scores):\n",
        "    axes[0].text(v + 0.01, i, f'{v:.4f}', va='center')\n",
        "\n",
        "# 2.2 RMSE\n",
        "axes[1].barh(models, rmse_scores, color='coral')\n",
        "axes[1].set_xlabel('RMSE (kWh)')\n",
        "axes[1].set_title('So s√°nh RMSE')\n",
        "axes[1].grid(True, alpha=0.3, axis='x')\n",
        "for i, v in enumerate(rmse_scores):\n",
        "    axes[1].text(v + 0.5, i, f'{v:.2f}', va='center')\n",
        "\n",
        "# 2.3 MAPE\n",
        "axes[2].barh(models, mape_scores, color='lightgreen')\n",
        "axes[2].set_xlabel('MAPE (%)')\n",
        "axes[2].set_title('So s√°nh MAPE')\n",
        "axes[2].grid(True, alpha=0.3, axis='x')\n",
        "for i, v in enumerate(mape_scores):\n",
        "    axes[2].text(v + 0.2, i, f'{v:.2f}', va='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Bi·ªÉu ƒë·ªì 3: Feature Importance (n·∫øu l√† tree-based model)\n",
        "if best_model_name in ['Random Forest', 'Gradient Boosting', 'XGBoost']:\n",
        "    print(f\"\\n[Feature Importance] {best_model_name}\")\n",
        "\n",
        "    if hasattr(best_model, 'feature_importances_'):\n",
        "        importances = best_model.feature_importances_\n",
        "        feature_names = selected_features\n",
        "\n",
        "        # S·∫Øp x·∫øp theo ƒë·ªô quan tr·ªçng\n",
        "        indices = np.argsort(importances)[::-1][:15]  # Top 15\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.barh(range(len(indices)), importances[indices], color='teal')\n",
        "        plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "        plt.xlabel('ƒê·ªô quan tr·ªçng')\n",
        "        plt.title(f'Top 15 ƒë·∫∑c tr∆∞ng quan tr·ªçng nh·∫•t ({best_model_name})')\n",
        "        plt.gca().invert_yaxis()\n",
        "        plt.grid(True, alpha=0.3, axis='x')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "KrXNrjGe5PaE"
      },
      "id": "KrXNrjGe5PaE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9. K·∫æT LU·∫¨N V√Ä KHUY·∫æN NGH·ªä**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "1-UAO1Dz5ZzT"
      },
      "id": "1-UAO1Dz5ZzT"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\"\"\n",
        " T√ìM T·∫ÆT K·∫æT QU·∫¢:\n",
        "--------------------------------------------------\n",
        "M√¥ h√¨nh t·ªët nh·∫•t: {best_model_name}\n",
        "- R¬≤ Score: {df_summary.iloc[0]['R2_Test']:.4f} (Gi·∫£i th√≠ch {df_summary.iloc[0]['R2_Test']*100:.2f}% ph∆∞∆°ng sai)\n",
        "- RMSE: {df_summary.iloc[0]['RMSE_Test']:.2f} kWh/ng√†y\n",
        "- MAE: {df_summary.iloc[0]['MAE_Test']:.2f} kWh/ng√†y\n",
        "- MAPE: {df_summary.iloc[0]['MAPE_Test (%)']:.2f}%\n",
        "- Sai s·ªë t·ªïng h√≥a ƒë∆°n: {df_summary.iloc[0]['Total_Err_Test (%)']:.2f}%\n",
        "\n",
        " PH√ÇN T√çCH:\n",
        "--------------------------------------------------\n",
        "1. ƒê·ªô ch√≠nh x√°c:\n",
        "   - Sai s·ªë trung b√¨nh m·ªói ng√†y: ¬±{df_summary.iloc[0]['MAE_Test']:.2f} kWh\n",
        "   - T·ª∑ l·ªá sai l·ªách: {df_summary.iloc[0]['MAPE_Test (%)']:.2f}%\n",
        "   - V·ªõi h√≥a ƒë∆°n 30 ng√†y, sai s·ªë d·ª± ki·∫øn: {df_summary.iloc[0]['Total_Err_Test (%)']:.2f}%\n",
        "\n",
        "2. ƒê·∫∑c tr∆∞ng quan tr·ªçng:\n",
        "   - C√°c lag features (lag_1, lag_7) c√≥ ·∫£nh h∆∞·ªüng l·ªõn\n",
        "   - ƒê·∫∑c tr∆∞ng rolling window gi√∫p b·∫Øt xu h∆∞·ªõng\n",
        "   - Nhi·ªát ƒë·ªô v√† ng√†y l·ªÖ c√≥ t√°c ƒë·ªông ƒë√°ng k·ªÉ\n",
        "\n",
        "3. So s√°nh c√°c m√¥ h√¨nh:\n",
        "   - {best_model_name} v∆∞·ª£t tr·ªôi v·ªÅ kh·∫£ nƒÉng d·ª± b√°o\n",
        "   - Linear models ph√π h·ª£p n·∫øu c·∫ßn t·ªëc ƒë·ªô cao\n",
        "   - Tree-based models b·∫Øt ƒë∆∞·ª£c phi tuy·∫øn t√≠nh t·ªët h∆°n\n",
        "\n",
        " H·∫†N CH·∫æ:\n",
        "--------------------------------------------------\n",
        "1. D·ªØ li·ªáu nhi·ªát ƒë·ªô ch·ªâ l√† proxy (∆∞·ªõc l∆∞·ª£ng theo th√°ng)\n",
        "2. Kh√¥ng c√≥ th√¥ng tin v·ªÅ gi√° ƒëi·ªán theo gi·ªù\n",
        "3. Recursive forecasting t√≠ch l≈©y sai s·ªë theo th·ªùi gian\n",
        "4. Ch∆∞a x√©t c√°c s·ª± ki·ªán ƒë·∫∑c bi·ªát (d·ªãch b·ªánh, kh·ªßng ho·∫£ng nƒÉng l∆∞·ª£ng)\n",
        "\n",
        " H∆Ø·ªöNG C·∫¢I TI·∫æN:\n",
        "--------------------------------------------------\n",
        "1. Thu th·∫≠p d·ªØ li·ªáu th·ªùi ti·∫øt th·ª±c t·∫ø (API)\n",
        "2. Th√™m d·ªØ li·ªáu gi√° ƒëi·ªán theo khung gi·ªù\n",
        "3. S·ª≠ d·ª•ng m√¥ h√¨nh LSTM/Prophet cho chu·ªói th·ªùi gian\n",
        "4. K·∫øt h·ª£p ensemble c·ªßa nhi·ªÅu m√¥ h√¨nh\n",
        "5. Th√™m d·ªØ li·ªáu v·ªÅ c√°c s·ª± ki·ªán l·ªõn (COVID-19, l·ªÖ h·ªôi)\n",
        "6. √Åp d·ª•ng cross-validation chu·ªói th·ªùi gian (Time Series CV)\n",
        "\n",
        " ·ª®NG D·ª§NG TH·ª∞C T·∫æ:\n",
        "--------------------------------------------------\n",
        "- T·ªëi ∆∞u h√≥a mua ƒëi·ªán cho doanh nghi·ªáp\n",
        "- D·ª± b√°o nhu c·∫ßu nƒÉng l∆∞·ª£ng cho grid management\n",
        "- Ph√°t hi·ªán b·∫•t th∆∞·ªùng trong ti√™u th·ª• ƒëi·ªán\n",
        "- L·∫≠p k·∫ø ho·∫°ch b·∫£o tr√¨ thi·∫øt b·ªã ƒëi·ªán\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" HO√ÄN T·∫§T TO√ÄN B·ªò QUY TR√åNH D·ª∞ B√ÅO\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "43Kdg9pg5ixi"
      },
      "id": "43Kdg9pg5ixi",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}